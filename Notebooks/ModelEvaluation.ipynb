{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ModelEvaluation.ipynb","provenance":[{"file_id":"1v3nzYh32q2rm7aqOaUDvqZVUmShicAsT","timestamp":1610298880584}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WzgPkIP1irG3"},"source":["# Object Detection in Google Colab with Fizyr Retinanet\n","\n","Jupyter notebook providing steps to train a Keras/Tensorflow model for object detection with custom dataset.\n","\n","It runs in Google Colab using [Fizyr implementation](https://github.com/fizyr/keras-retinanet) of RetinaNet in Keras.\n","\n","Requirements are only dataset images and annotations file made in [LabelImg](https://github.com/tzutalin/labelImg).\n","\n","Colab Runtime type: Python3, GPU enabled."]},{"cell_type":"markdown","metadata":{"id":"J6D_Wz3h5ILS"},"source":["# Environment Setup\n","Download and install in Colab required packages and import libraries."]},{"cell_type":"code","metadata":{"id":"3PdMj4Tn3tgN"},"source":["!git clone https://github.com/fizyr/keras-retinanet.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uPLMzdXZ5BGB"},"source":["%cd keras-retinanet/\n","\n","!pip install ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UWspmGibv2qq"},"source":["!python setup.py build_ext --inplace"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9UI7XYyxyJcX"},"source":["import os\n","import shutil\n","import zipfile\n","import urllib\n","import urllib.request\n","import xml.etree.ElementTree as ET\n","import numpy as np\n","import csv\n","import pandas\n","from google.colab import drive\n","from google.colab import files"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jiIEhwOx8Box"},"source":["# Making Dataset\n","\n","We will be using HyperLabel to create our dataset. You can watch the following tutorial video about how to use HyperLabel and tag images with it.\n","\n","https://www.youtube.com/embed/R56Ck3tElIs\n","\n","Once all of your images are tagged, its time to export the labels and data in Pascal VOC format. Goto the `review` tab/section and click on the export button. From the export menu, choose `Object Detection` and select Pascal VOC and click on export. It will take some time to export the data, once exported you should be able to see multiple folders, but we are interested in two i.e., `Annotations` and `JPEGImages` folder.\n","\n","Now created a new folder, name it `dataset`. Copy all the contents of `Annotations` folder and `JPEGImages` folder inside `dataset` folder and then create a zip archive of this folder.\n","\n","Upload this zip archive to your Google drive and get the ID. To locate the File ID, right click on the name of the file, choose the Get Shareable Link option, and turn on Link Sharing if needed (you can turn it off later). You will see the link with a combination of numbers and letters at the end, and what you see after id =   is the File ID.\n","\n","https://drive.google.com/open?id=***ThisIsFileID*** \n","\n","If your file is already open in a browser, you can obtain File ID from its link:\n","\n","https://docs.google.com/spreadsheets/d/***ThisIsFileID***/edit#gid=123456789 "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wzVddmkNU1-I","executionInfo":{"status":"ok","timestamp":1610786861177,"user_tz":-120,"elapsed":96909,"user":{"displayName":"Omri Manor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2EptM7IZb6sUNxw99JKmStEdhFSJUQ09xoe-t=s64","userId":"04725865312433508858"}},"outputId":"981073a3-cb92-48bf-e17b-9bda8110209c"},"source":["! git clone https://github.com/omrimanor7/TrafficSignDetection2021.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'TrafficSignDetection2021'...\n","remote: Enumerating objects: 34, done.\u001b[K\n","remote: Counting objects: 100% (34/34), done.\u001b[K\n","remote: Compressing objects: 100% (28/28), done.\u001b[K\n","remote: Total 2195 (delta 8), reused 26 (delta 4), pack-reused 2161\u001b[K\n","Receiving objects: 100% (2195/2195), 1.60 GiB | 25.04 MiB/s, done.\n","Resolving deltas: 100% (11/11), done.\n","Checking out files: 100% (2131/2131), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vt4ojaUckMsG"},"source":["CLASSES_FILE = \"/content/keras-retinanet/TrafficSignDetection2021/FullIJCNN2013/classes.csv\"\n","ANNOTATIONS_FILE = \"/content/keras-retinanet/TrafficSignDetection2021/FullIJCNN2013/annotations.csv\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KGtn3JW6Mig8"},"source":["# Training Model\n","\n","Download pretrained model and run training.\n","\n","In the next cell choose one option:\n","\n","1.   download Fizyr Resnet50 pretrained model\n","2.   download your custom pretrained model, to continue previous training epochs\n","\n","In the last cell optionally export trained model to Google Drive.\n"]},{"cell_type":"code","metadata":{"id":"LXQzV1yhz3jI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610786887472,"user_tz":-120,"elapsed":105166,"user":{"displayName":"Omri Manor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2EptM7IZb6sUNxw99JKmStEdhFSJUQ09xoe-t=s64","userId":"04725865312433508858"}},"outputId":"ccb31ab9-ef77-490f-cdcd-8d9be75aec15"},"source":["PRETRAINED_MODEL = './snapshots/_pretrained_model.h5'\n","\n","#### OPTION 1: DOWNLOAD INITIAL PRETRAINED MODEL FROM FIZYR ####\n","# URL_MODEL = 'https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5'\n","# URL_MODEL = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","# urllib.request.urlretrieve(URL_MODEL, PRETRAINED_MODEL)\n","\n","#### OPTION 2: DOWNLOAD CUSTOM PRETRAINED MODEL FROM GOOGLE DRIVE. CHANGE DRIVE_MODEL VALUE. USE THIS TO CONTINUE PREVIOUS TRAINING EPOCHS ####\n","drive.mount('/content/gdrive')\n","DRIVE_MODEL = '/content/gdrive/My Drive/EE Final Project/ResNetModels/resnet50_csv_01.h5'\n","shutil.copy(DRIVE_MODEL, './snapshots/resnet50_csv_01.h5')\n","\n","print('Downloaded pretrained model to ' + PRETRAINED_MODEL)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","Downloaded pretrained model to ./snapshots/_pretrained_model.h5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_bexsEvq_zb6"},"source":["# !keras_retinanet/bin/train.py --freeze-backbone --random-transform --weights {PRETRAINED_MODEL} --batch-size 1 --steps 900 --epochs 1 csv {ANNOTATIONS_FILE} {CLASSES_FILE}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SY84pZG5rCVl"},"source":["SNAPSHOT = './snapshots/resnet50_csv_01.h5'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u7-MVuFYu8gE"},"source":["!keras_retinanet/bin/train.py --freeze-backbone --random-transform --snapshot {SNAPSHOT} --batch-size 1 --steps 300 --epochs 1 csv {ANNOTATIONS_FILE} {CLASSES_FILE}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"vgfE5aDQHFz8","executionInfo":{"status":"ok","timestamp":1610786889660,"user_tz":-120,"elapsed":2090,"user":{"displayName":"Omri Manor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2EptM7IZb6sUNxw99JKmStEdhFSJUQ09xoe-t=s64","userId":"04725865312433508858"}},"outputId":"4db9e46f-d134-4435-c2d6-e84de5fd4ddb"},"source":["#### OPTIONAL: EXPORT TRAINED MODEL TO DRIVE ####\n","drive.mount('/content/gdrive')\n","COLAB_MODEL = './snapshots/resnet50_csv_01.h5'\n","DRIVE_DIR = '/content/gdrive/My Drive/EE Final Project/ResNetModels/'\n","# shutil.copy(COLAB_MODEL, DRIVE_DIR)\n","DRIVE_MODEL = DRIVE_DIR + 'resnet50_csv_01.h5'\n","shutil.copy(DRIVE_MODEL, COLAB_MODEL)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'./snapshots/resnet50_csv_01.h5'"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"QG1QxXAVHTcA"},"source":["import sys\n","import runpy\n","sys.argv = f\"keras_retinanet/bin/train.py --freeze-backbone --random-transform --snapshot {SNAPSHOT} --batch-size 1 --steps 700 --epochs 1 csv {ANNOTATIONS_FILE} {CLASSES_FILE}\".split()\n","import subprocess\n","\n","while True:\n","  subprocess.call(sys.argv)\n","  shutil.copy(COLAB_MODEL, DRIVE_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p1QimaHHh_M0"},"source":["# Inference\n","Run inference with uploaded image on trained model."]},{"cell_type":"code","metadata":{"id":"Wfsj1KOVzTdi"},"source":["THRES_SCORE = 0.6"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cYyfa8yniJiW"},"source":["# show images inline\n","%matplotlib inline\n","\n","# automatically reload modules when they have changed\n","%reload_ext autoreload\n","%autoreload 2\n","\n","# import keras\n","import keras\n","\n","# import keras_retinanet\n","from keras_retinanet import models\n","from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n","from keras_retinanet.utils.visualization import draw_box, draw_caption\n","from keras_retinanet.utils.colors import label_color\n","\n","# import miscellaneous modules\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","import numpy as np\n","import time\n","\n","# set tf backend to allow memory to grow, instead of claiming everything\n","import tensorflow as tf\n","\n","def get_session():\n","    config = tf.compat.v1.ConfigProto()\n","    config.gpu_options.allow_growth = True\n","    return tf.compat.v1.Session(config=config)\n","\n","# use this environment flag to change which GPU to use\n","#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n","\n","# set the modified tf session as backend in keras\n","tf.compat.v1.keras.backend.set_session(get_session())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GkewNh9UiOs1","executionInfo":{"status":"ok","timestamp":1610786901133,"user_tz":-120,"elapsed":13530,"user":{"displayName":"Omri Manor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2EptM7IZb6sUNxw99JKmStEdhFSJUQ09xoe-t=s64","userId":"04725865312433508858"}},"outputId":"e442c601-6210-4c54-f9a5-4fcf055b4baa"},"source":["model_path = DRIVE_MODEL\n","print(model_path)\n","\n","# load retinanet model\n","model = models.load_model(model_path, backbone_name='resnet50')\n","model = models.convert_model(model)\n","\n","# load label to names mapping for visualization purposes\n","labels_to_names = pandas.read_csv(CLASSES_FILE,header=None).T.loc[0].to_dict()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/EE Final Project/ResNetModels/resnet50_csv_01.h5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rWSHqP1KTHxQ"},"source":["def img_inference(img_path):\n","  image = read_image_bgr(img_infer)\n","\n","  # copy to draw on\n","  draw = image.copy()\n","  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n","\n","  # preprocess image for network\n","  image = preprocess_image(image)\n","  image, scale = resize_image(image)\n","\n","  # process image\n","  start = time.time()\n","  boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n","  print(\"processing time: \", time.time() - start)\n","\n","  # correct for image scale\n","  boxes /= scale\n","\n","  # visualize detections\n","  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n","      \n","      # print(label)\n","      \n","      # scores are sorted so we can break\n","      if score < THRES_SCORE:\n","          break\n","\n","      color = label_color(label)\n","\n","      b = box.astype(int)\n","      draw_box(draw, b, color=color)\n","\n","      caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n","      print(caption)\n","      draw_caption(draw, b, caption)\n","\n","  plt.figure(figsize=(20, 20))\n","  plt.axis('off')\n","  plt.imshow(draw)\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I_AoWG4lHFME"},"source":["# GTSDB\n","\n","\n","# uploaded = files.upload()\n","# img_infer = list(uploaded)[0]\n","# img_inference(img_infer)\n","\n","test_imgs_indecies = np.random.randint(0, 900, 10)\n","for i in test_imgs_indecies:\n","  img_infer = '/content/keras-retinanet/TrafficSignDetection2021/FullIJCNN2013/' + str(i).zfill(5)  + '.ppm'\n","  print('Running inference on: ' + img_infer)\n","  img_inference(img_infer)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4RbkuKPkarIy"},"source":["# chinese\n","\n","\n","# uploaded = files.upload()\n","# img_infer = list(uploaded)[0]\n","# img_inference(img_infer)\n","\n","test_imgs_indecies = np.random.randint(1, 100, 10)\n","for i in test_imgs_indecies:\n","  img_infer = '/content/gdrive/MyDrive/EE Final Project/chineseDataset/test_image/test (' + str(i)  + ').bmp'\n","  print('Running inference on: ' + img_infer)\n","  img_inference(img_infer)\n","\n","\n"],"execution_count":null,"outputs":[]}]}